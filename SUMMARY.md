# Summary

* [Introduction](README.md)
* [The Reinforcement Learning](chapter1.md)
* [Multi-arm Bandits](part1/chapter2/2_0.md)
   * [An n-Armed Bandit Problem](part1/chapter2/2_1.md)
   * [Action-Value Methods](part1/chapter2/2_2.md)
   * [Incremental Implementation](part1/chapter2/2_3.md)
   * [Tracking a Nonstationary Problem](part1/chapter2/2_4.md)
   * [Optimistic Initial Values](part1/chapter2/2_5.md)
   * [UCB Action Selection](part1/chapter2/2_6.md)
   * [Gradient Bandits](part1/chapter2/2_7.md)
   * [Associative Search](part1/chapter2/2_8.md)
* [Finite Markov Decision Processes](part1/chapter3/3_0.md)
   * [The Agent-Environment Interface](part1/chapter3/3_1.md)
   * [Goals and Rewards](part1/chapter3/3_2.md)
   * [Returns](part1/chapter3/3_3.md)
   * [Unified Notation](part1/chapter3/3_4.md)
   * [The Markov Property](part1/chapter3/3_5.md)
   * [Markov Decision Processes](part1/chapter3/3_6.md)
   * [Value Functions](part1/chapter3/3_7.md)
   * [Optimality Optimal Value Functions](part1/chapter3/3_8.md)
   * [Optimality and Approximation](part1/chapter3/3_9.md)
* [Dynamic Programming](part1/chapter4/4_0.md)
   * [Policy Evaluation](part1/chapter4/4_1.md)
   * [Policy Improvement](part1/chapter4/4_2.md)
   * [Policy Iteration](part1/chapter4/4_3.md)
   * [Value Iteration](part1/chapter4/4_4.md)
   * [Asynchronous DP](part1/chapter4/4_5.md)
   * [Generalized Policy Iteration](part1/chapter4/4_6.md)
   * [Efficiency of DP](part1/chapter4/4_7.md)
* [Monte Carlo Methods](part1/chapter5/5_0.md)
   * [Monte Carlo Prediction](part1/chapter5/5_1.md)
   * [MC Estimation of Action values](part1/chapter5/5_2.md)
   * [MC Control](part1/chapter5/5_3.md)
   * [MC Control without Exploring Starts](part1/chapter5/5_4.md)
